{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "688abd61-a467-4b6f-ba65-4bf9fcd63ef5",
   "metadata": {},
   "source": [
    "# Do multi-round matches\n",
    "\n",
    "We use a greedy algorithm: we do best matches first, then we ban further pairwise matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3425d64-828a-4905-9047-60ab00c796fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of registered users: 1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1162it [03:01,  6.41it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "import hcluster   # requires dedupe-hcluster\n",
    "from paper_reviewer_matcher import (\n",
    "    preprocess, compute_affinity\n",
    ")\n",
    "\n",
    "from group_matching import compute_conflicts, generate_pod_numbers\n",
    "\n",
    "users = pd.read_csv('data/mindmatch_example.csv').to_dict(orient='records')\n",
    "n_users = len(users)\n",
    "print('Number of registered users: {}'.format(n_users))\n",
    "\n",
    "users_df = pd.DataFrame(users).fillna('')\n",
    "users_dict = {r['user_id']: dict(r) for _, r in users_df.iterrows()}  # map of user id to details\n",
    "persons_1 = list(map(preprocess, list(users_df['abstracts'])))\n",
    "persons_2 = list(map(preprocess, list(users_df['abstracts'])))\n",
    "A = compute_affinity(\n",
    "    persons_1, persons_2,\n",
    "    n_components=30, min_df=2, max_df=0.8,\n",
    "    weighting='tfidf', projection='svd'\n",
    ")\n",
    "cois_list = compute_conflicts(users_df)\n",
    "for i, j in cois_list:\n",
    "    A[i, j] = -1\n",
    "\n",
    "A_cluster = - A\n",
    "A_cluster[A_cluster == 1000] = 1\n",
    "A0 = A_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5db74c1f-64c8-4c23-ac08-105172cbd14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_goodness(A_cluster, cluster_assignments):\n",
    "    dists = []\n",
    "    for i in range(cluster_assignments.min(), cluster_assignments.max()+1):\n",
    "        # Calculate the average pairwise distance within the cluster.\n",
    "        mean_dist = A_cluster[cluster_assignments == i, :][:, cluster_assignments == i].mean()\n",
    "        dists.append(mean_dist)\n",
    "        \n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1225271c-d201-402e-91d6-fff5d254143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We apply the alternative bottom-up method suggested here\n",
    "# https://github.com/jmonlong/Hippocamplus/blob/master/content/post/2018-06-09-ClusterEqualSize.Rmd\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "def get_distance_vector(B):\n",
    "    Bs = (B + B.T) / 2.0\n",
    "    diag_mask = (np.ones_like(Bs) - np.eye(Bs.shape[0]))\n",
    "    Bs = Bs * diag_mask\n",
    "    return squareform(Bs)\n",
    "\n",
    "def agglomerate(A, group_size):\n",
    "    ngroups = int(np.ceil(A.shape[0] / group_size))\n",
    "    nsmallgroups = ngroups * group_size - A.shape[0]\n",
    "    nbiggroups = ngroups - nsmallgroups\n",
    "    labels = np.ones(A.shape[0]) * np.nan\n",
    "    \n",
    "    A = A.copy()\n",
    "    \n",
    "    groups = []\n",
    "    group_sizes = [group_size] * nbiggroups + [group_size - 1] * nsmallgroups\n",
    "    assert A.shape[0] == sum(group_sizes)\n",
    "    j = 0\n",
    "    for gs in tqdm(group_sizes):\n",
    "        B = A[np.isnan(labels), :][:, np.isnan(labels)]\n",
    "        z = linkage(get_distance_vector(B),\n",
    "                    method='average',\n",
    "                    metric='euclidean')\n",
    "        \n",
    "        the_nums = np.where(z[:, -1] >= gs)[0]\n",
    "        minpos = the_nums.min()\n",
    "        \n",
    "        cluster_nums = [z[minpos, 0], z[minpos, 1]]\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(cluster_nums):\n",
    "            if cluster_nums[i] >= B.shape[0]:\n",
    "                cluster_nums.append(z[int(cluster_nums[i]) - B.shape[0], 0])\n",
    "                cluster_nums.append(z[int(cluster_nums[i]) - B.shape[0], 1])\n",
    "            i += 1\n",
    "            \n",
    "        cluster_nums = np.array(cluster_nums).astype(int)\n",
    "        cluster_nums = cluster_nums[cluster_nums < B.shape[0]]\n",
    "        \n",
    "        assert len(cluster_nums) >= gs\n",
    "        cluster_nums = cluster_nums[:gs]\n",
    "        \n",
    "        # Map cluster nums to the original numbers prior to subsetting.\n",
    "        the_map = np.where(np.isnan(labels))[0]        \n",
    "        cluster_nums = [the_map[k] for k in cluster_nums]\n",
    "        labels[cluster_nums] = j        \n",
    "        j += 1\n",
    "        \n",
    "    return labels.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad5ce6fa-ec17-4eea-a045-9b79e7379cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 233/233 [00:01<00:00, 158.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20721110253896619, 0.05313283490597109]\n",
      "6064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 233/233 [00:01<00:00, 166.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23253462354067633, 0.05266612920988387]\n",
      "10692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 233/233 [00:01<00:00, 165.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2426361171008488, 0.057776939786365375]\n",
      "15310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 233/233 [00:01<00:00, 170.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.251461187332032, 0.0577577764271906]\n"
     ]
    }
   ],
   "source": [
    "# Ban previous match sets\n",
    "A = A0.copy()\n",
    "\n",
    "print((A == 1).sum())\n",
    "\n",
    "labels = agglomerate(A, 5)\n",
    "goodnesses = np.array(measure_goodness(A0, labels))\n",
    "print([goodnesses.mean(), np.std(goodnesses)])\n",
    "\n",
    "for j in range(3):\n",
    "    for i in range(labels.max()+1):\n",
    "        a = np.where(labels==i)[0]\n",
    "        for k in a:\n",
    "            A[labels==i, k] = 1\n",
    "            \n",
    "    print((A == 1).sum())\n",
    "\n",
    "    labels = agglomerate(A, 5)\n",
    "\n",
    "    goodnesses = np.array(measure_goodness(A0, labels))\n",
    "    print([goodnesses.mean(), np.std(goodnesses)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
